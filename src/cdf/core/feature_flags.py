"""Feature flags for CDF.

NOTE: our primary usage pattern of FF is to get a bunch of flags
for a single component, so we should optimize for that
This means we may not need to pull every possible flag into
the cache. Thus our main entrypoint should be something like
get_component_ff(component_id: str, populate_cache_fn=get_or_create_flag_dispatch)

component_id = <source|transform|publisher>:<name>
flag_name = <component_id>:<flag_name>
"""
import json
import logging
import typing as t
from contextlib import suppress
from functools import lru_cache
from pathlib import Path
from threading import Lock

import dlt
from dlt.extract.source import DltSource
from dlt.sources.helpers import requests
from featureflags.client import CfClient, Config, Target
from featureflags.evaluations.enum import FeatureState  # noqa: F401
from featureflags.evaluations.feature import FeatureConfig  # noqa: F401
from featureflags.evaluations.feature import FeatureConfigKind
from featureflags.interface import Cache
from featureflags.util import log as _ff_logger

import cdf.core.constants as c
import cdf.core.logger as cdf_logger
from cdf.core.types import Result
from cdf.core.utils import get_source_component_id, qualify_source_component_id

TFlags = t.Dict[str, bool]
TFlagsSource = t.Dict[DltSource, TFlags]
FnPopulateCache = t.Callable[[TFlags, DltSource, str, Path], TFlags]
Providers = t.Literal["local", "harness", "launchdarkly"]


CACHE: TFlagsSource = {}
_LOCAL_CACHE_MUTEX = Lock()


class _Cache(dict, Cache):
    """This exists because the default harness LRU impl sucks and does not work with >1000 flags"""

    def set(self, key: str, value: bool) -> None:
        """Set a flag in the cache."""
        self[key] = value

    def remove(self, key) -> None:
        """Remove a flag from the cache."""
        self.pop(key, None)


@lru_cache(maxsize=1)
def _get_harness_client(
    sdk_key: str | None = None,
) -> CfClient:
    """Get a harness client. This is cached so we don't have to create a new client.

    Args:
        sdk_key: The sdk key to use to authenticate with harness.

    Returns:
        The client.
    """
    client = CfClient(
        sdk_key=sdk_key or dlt.secrets["ff.harness.sdk_key"],
        config=Config(enable_stream=False, enable_analytics=False, cache=_Cache()),
    )
    client.wait_for_initialization()
    return client


def _harness_identifiers(
    account: bool = True,
    organization: bool = True,
    project: bool = True,
    environment: bool = False,
) -> t.Dict[str, str]:
    """Get the identifiers for the Harness Platform API"""
    identifiers = {}
    if account:
        identifiers["accountIdentifier"] = dlt.config["ff.harness.account"]
    if organization:
        identifiers["orgIdentifier"] = dlt.config["ff.harness.organization"]
    if project:
        identifiers["projectIdentifier"] = dlt.config["ff.harness.project"]
    if environment:
        identifiers["environmentIdentifier"] = dlt.config["ff.harness.environment_id"]
    return identifiers


def _create_harness_flag(
    identifier: str,
    name: str,
    api_key: str | None = None,
    description: str = "Autogenerated - do not edit",
    kind: FeatureConfigKind = FeatureConfigKind.BOOLEAN,
    variations: t.Optional[t.List[t.Dict[str, str]]] = None,
    **kwargs: t.Any,
) -> Result[dict]:
    """Create a flag in the Harness Platform API

    Args:
        identifier (str): The identifier for the flag
        name (str): The name for the flag
        kind (FeatureConfigKind): The kind of flag
        variations (dict): The variations for the flag
        **kwargs: Additional keyword arguments to pass to the Harness Platform API

    Returns:
        dict: The response from the Harness Platform API

    Raises:
        AssertionError: If the number of variations is less than two
        requests.exceptions.HTTPError: If the response from the Harness Platform API
            is not successful
    """
    if variations is None:
        variations = [
            {
                "identifier": "on-variation",
                "value": "true",
            },
            {
                "identifier": "off-variation",
                "value": "false",
            },
        ]
    assert len(variations) >= 2, "Must have at least two variations"
    resp = requests.post(
        "https://app.harness.io/gateway/cf/admin/features",
        params=_harness_identifiers(project=False),
        headers={
            "Content-Type": "application/json",
            "x-api-key": api_key or dlt.secrets["ff.harness.api_key"],
        },
        json={
            "defaultOnVariation": variations[0]["identifier"],
            "defaultOffVariation": variations[1]["identifier"],
            "description": description,
            "identifier": identifier,
            "name": name,
            "kind": kind.value,
            "permanent": True,
            "project": dlt.config["ff.harness.project"],
            "variations": variations,
            **kwargs,
        },
    )
    if resp.ok:
        return Result(resp.json(), None)
    return Result(None, Exception(resp.text))


@lru_cache(maxsize=1)
def _get_harness_flag(flag_id: str, api_key: str | None = None) -> Result[dict]:
    """Get a flag from the Harness Platform API

    Args:
        flag_id (str): The flag identifier

    Returns:
        dict: The flag

    Raises:
        requests.exceptions.HTTPError: If the request fails
    """
    resp = requests.get(
        f"https://app.harness.io/gateway/cf/admin/features/{flag_id}",
        headers={"x-api-key": api_key or dlt.secrets["ff.harness.api_key"]},
        params={**_harness_identifiers(environment=True), "metrics": False},
    )
    if resp.ok:
        return Result(resp.json(), None)
    return Result(None, Exception(resp.text))


def _harness_flag_exists(flag_id: str, ff_client: CfClient) -> bool:
    """Check if a flag exists in the Harness Platform API

    We make this fast by checking the SDK cache.

    Args:
        flag_id (str): The identifier for the flag

    Returns:
        bool: True if the flag exists, False otherwise
    """
    try:
        return f"flags/{flag_id}" in list(ff_client._repository.cache.keys()) or bool(
            Result.apply(_get_harness_flag, flag_id)
        )
    except requests.HTTPError as e:
        if e.response and e.response.status_code in (404, 400):
            return False
        raise


def _harness_id_to_component_id(harness_id: str) -> str:
    """Convert a Harness Platform API flag id to a component id

    Args:
        harness_id (str): The Harness Platform API flag id

    Returns:
        str: The component id
    """
    # workspace_X_source__resource -> source:workspace.source:resource
    if harness_id.upper().startswith("FLAGS/"):
        harness_id = harness_id.split("/", 1)[1]
    return "source:" + harness_id.replace("_X_", ".", 1).replace("__", ":", 1)


def _component_id_to_harness_id(component_id: str) -> str:
    """Convert a component id to a Harness Platform API flag id

    Args:
        component_id (str): The component id

    Returns:
        str: The Harness Platform API flag id
    """
    # source:workspace.source:resource -> workspace_X_source__resource
    return "__".join(component_id.split(":")[1:]).replace(".", "_X_")


def get_or_create_flag_harness(
    cache: TFlags,
    source: DltSource,
    /,
    workspace_name: str,
    workspace_path: Path,
    *,
    account: str | None = None,
    project: str | None = None,
    organization: str | None = None,
    sdk_key: str | None = None,
    api_key: str | None = None,
) -> TFlags:
    """Populate a cache with flags.

    Args:
        cache: A cache to populate.
        component_id: The id of the component to search for flags. Used to reduce the
            number of fetched flags. Additionally, if a flag for the given component id
            does not exist, we will create it.
        sdk_key: The sdk key to use to authenticate with harness.

    Returns:
        dict: The populated cache.
    """
    _ = workspace_path  # We don't need the path
    _ff_logger.setLevel(logging.ERROR)
    cache = cache if cache is not None else {}
    ff_client = _get_harness_client(sdk_key or dlt.secrets["ff.harness.sdk_key"])
    account, project, organization = (
        account or dlt.config["ff.harness.account"],
        project or dlt.config["ff.harness.project"],
        organization or dlt.config["ff.harness.organization"],
    )
    cache.update(
        {
            _harness_id_to_component_id(k): ff_client.bool_variation(
                k[6:], Target("cdf"), False
            )
            for k in ff_client._repository.cache.keys()
        }
    )
    for resource in source.resources.keys():
        component = get_source_component_id(source, resource, workspace_name)
        if component in cache:
            continue
        harness_safeident = _component_id_to_harness_id(component)
        exists = _harness_flag_exists(harness_safeident, ff_client)
        if not exists:
            _create_harness_flag(
                harness_safeident,
                f"Extract {' '.join(component.split(':')[1:]).title()}",
                api_key=api_key or dlt.secrets["ff.harness.api_key"],
            )
            cache[component] = False
        else:
            rv = ff_client.bool_variation(harness_safeident, Target("cdf"), False)
            cache[component] = rv
    return cache


def get_or_create_flag_launchdarkly(
    cache: TFlags,
    source: DltSource,
    /,
    workspace_name: str,
    workspace_path: Path,
    *,
    account: str | None = None,
    api_key: str | None = None,
) -> TFlags:
    raise NotImplementedError


def get_or_create_flag_local(
    cache: TFlags,
    source: DltSource,
    /,
    workspace_name: str,
    workspace_path: Path,
    *,
    component_paths: t.Iterable[str | Path] | None = None,
) -> TFlags:
    """Populate a cache with flags.

    Args:
        cache: A cache to populate.
        source: The DltSource to get flags for.
        workspace_name: The name of the workspace.
        workspace_path: The path to the workspace.
        component_paths: The paths to search for flags. These are relative to the
            workspace path. If None, the default cdf layout paths are used.
        max_depth: The maximum depth to search for flags.

    Returns:
        dict: The populated cache.
    """
    cache = cache if cache is not None else {}
    component_paths_: t.List[Path] = [
        workspace_path / c.SOURCES_PATH,
        Path.home() / ".cdf",
    ]

    for path in component_paths_:
        cdf_logger.debug("Searching for flags in %s", path)
        flags = {}

        # Set search depth
        if workspace_path not in path.parents:
            # User dir flags can only apply to the default workspace
            workspace_name = c.DEFAULT_WORKSPACE
            max_depth = path.parents.index(Path.home()) + 1
        elif workspace_path in path.parents:
            # Search up to project root
            max_depth = path.parents.index(workspace_path) + 1
        else:
            # We assume project root or explicit path
            max_depth = 0

        # Search
        depth, seen = 0, {}
        while path.parents and depth <= max_depth:
            for f in c.CDF_FLAG_FILES:
                fp = path / f
                if not fp.exists() or fp in seen:
                    continue
                seen[fp] = True
                fo = json.loads(fp.read_text())
                flags.update(fo)
            path = path.parent
            depth += 1

        # We want to ensure a single-project layout does not require default prefixed flags
        # And that in a multi-project layout, we can override flags with a working directory
        # based on the "project local" name. So we need to qualify the flags with the workspace.
        for key in list(flags.keys()):
            fqn = qualify_source_component_id(key, workspace_name)
            if fqn != key:
                cdf_logger.debug("Found flag %s, qualified as %s", key, fqn)
                flags[fqn] = flags.pop(key)

        cdf_logger.debug("Found flags: %s", flags)
        cache.update(flags)

    # TODO: make this a function
    with _LOCAL_CACHE_MUTEX:
        new_flags = {}
        for resource in source.resources.keys():
            component = get_source_component_id(source, resource, workspace_name)
            if component not in cache:
                new_flags[component] = False
        if new_flags:
            cdf_cwd = Path.cwd() / c.CDF_FLAG_FILES[0]
            cdf_logger.debug("Updating flags in %s", cdf_cwd)
            if cdf_cwd.exists():
                base_cwd_flags = json.loads(cdf_cwd.read_text())
                new_flags.update(base_cwd_flags)
            cdf_cwd.write_text(json.dumps(new_flags, indent=2))

    return cache


def toggle_flag_dispatch() -> Result:
    ...


def delete_flag_dispatch() -> Result:
    ...


def get_or_create_flag_dispatch(
    cache: TFlags,
    source: DltSource,
    /,
    workspace_name: str,
    workspace_path: Path,
    *,
    with_provider: Providers | None = None,
    **kwargs: t.Any,
) -> TFlags:
    """Populate a cache with flags.

    This function dispatches to the appropriate implementation based on the
    provider specified in the config.

    Args:
        cache: A cache to populate.
        source: The DltSource to get flags for.
        workspace_name: The name of the workspace.
        workspace_path: The path to the workspace.
        with_provider: The provider to use. If None, the provider from the config is used.
        **kwargs: Additional keyword arguments to pass to the implementation.

    Returns:
        dict: The populated cache.
    """
    kwargs["workspace_name"] = workspace_name
    kwargs["workspace_path"] = workspace_path
    provider = "local"
    with suppress(KeyError):
        provider: Providers = with_provider or dlt.config["ff.provider"]
    if provider == "local":
        return get_or_create_flag_local(cache, source, **kwargs)
    elif provider == "harness":
        return get_or_create_flag_harness(cache, source, **kwargs)
    elif provider == "launchdarkly":
        return get_or_create_flag_launchdarkly(cache, source, **kwargs)
    else:
        raise ValueError(
            f"Invalid provider: {provider}, must be one of {t.get_args(Providers)}"
        )


def get_source_flags(
    source: DltSource,
    populate_cache_fn: FnPopulateCache = get_or_create_flag_dispatch,
    cache: TFlagsSource | None = None,
    ns: str | None = None,
    path: str | Path | None = None,
) -> TFlags:
    """Get flags for a specific component id populating the cache if needed.

    Args:
        component_id: The component to find. In the form of <source|transform|publisher>:<name>
            For a source, the <name> is <source_name>:<resource_name>
        populate_cache_fn: A function which takes a cache dict and component id and populates
            the cache. The implementer can make decisions on how to interface with the network
            given the supplied component id which is a prefix for the requested flags. The
            implementer should also decide what to do if the component_id is not found in the
            cache. Typically this means creating a flag in the feature flag provider.

    Returns:
        dict: The flags for the source
    """
    if ns is None:
        ns = c.DEFAULT_WORKSPACE
    path = Path(path or ".").expanduser().resolve()
    cdf_logger.debug("Getting flags for %s in path %s", source.name, path)
    cache = cache if cache is not None else CACHE
    if source not in cache:
        cache[source] = populate_cache_fn({}, source, ns, path)
    return cache[source]


def apply_feature_flags(
    source: DltSource,
    flags: t.Dict[str, bool],
    workspace: str | None = None,
    raise_on_no_resources: bool = False,
) -> DltSource:
    """Apply feature flags to a source."""

    cdf_logger.debug("Applying feature flags for source %s", source.name)
    for resource in source.resources.values():
        key = get_source_component_id(source, resource, workspace)
        fv = flags.get(key)
        if fv is None:
            cdf_logger.debug("No flag for %s", key)
            fv = False
        elif fv is False:
            cdf_logger.debug("Flag for %s is False", key)
        elif fv is True:
            cdf_logger.debug("Flag for %s is True", key)
        resource.selected = fv

    if raise_on_no_resources and not source.resources.selected:
        raise ValueError(f"No resources selected for source {source.name}")

    return source
