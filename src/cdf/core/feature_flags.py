"""Feature flags for CDF.

NOTE: our primary usage pattern of FF is to get a bunch of flags
for a single component, so we should optimize for that
This means we may not need to pull every possible flag into
the cache. Thus our main entrypoint should be something like
get_component_ff(component_id: str, populate_cache_fn=get_or_create_flag_dispatch)

component_id = <source|transform|publisher>:<name>
flag_name = <component_id>:<flag_name>
"""
import json
import logging
import typing as t
from functools import lru_cache
from pathlib import Path
from threading import Lock

import dlt
from dlt.extract.source import DltSource
from dlt.sources.helpers import requests
from featureflags.client import CfClient, Config, Target
from featureflags.evaluations.enum import FeatureState  # noqa: F401
from featureflags.evaluations.feature import FeatureConfig  # noqa: F401
from featureflags.evaluations.feature import FeatureConfigKind
from featureflags.interface import Cache
from featureflags.util import log as _ff_logger

import cdf.core.constants as c
import cdf.core.logger as cdf_logger
from cdf.core.types import Result
from cdf.core.utils import (
    do,
    get_source_component_id,
    qualify_source_component_id,
    search_merge_json,
)

TFlags = t.Dict[str, bool]
TFlagsSource = t.Dict[DltSource, TFlags]
FnPopulateCache = t.Callable[[TFlags, DltSource, str, Path], TFlags]
Providers = t.Literal["local", "harness", "launchdarkly"]


CACHE: TFlagsSource = {}
_LOCAL_CACHE_MUTEX = Lock()


class _Cache(dict, Cache):
    """This exists because the default harness LRU impl sucks and does not work with >1000 flags"""

    def set(self, key: str, value: bool) -> None:
        """Set a flag in the cache."""
        self[key] = value

    def remove(self, key) -> None:
        """Remove a flag from the cache."""
        self.pop(key, None)


@lru_cache(maxsize=1)
def _get_harness_client(
    sdk_key: str | None = None,
) -> CfClient:
    """Get a harness client. This is cached so we don't have to create a new client.

    Args:
        sdk_key: The sdk key to use to authenticate with harness.

    Returns:
        The client.
    """
    client = CfClient(
        sdk_key=sdk_key or dlt.secrets["ff.harness.sdk_key"],
        config=Config(enable_stream=False, enable_analytics=False, cache=_Cache()),
    )
    client.wait_for_initialization()
    return client


def _harness_identifiers(
    account: bool = True,
    organization: bool = True,
    project: bool = True,
    environment: bool = False,
) -> t.Dict[str, str]:
    """Get the identifiers for the Harness Platform API"""
    identifiers = {}
    if account:
        identifiers["accountIdentifier"] = dlt.config["ff.harness.account"]
    if organization:
        identifiers["orgIdentifier"] = dlt.config["ff.harness.organization"]
    if project:
        identifiers["projectIdentifier"] = dlt.config["ff.harness.project"]
    if environment:
        identifiers["environmentIdentifier"] = dlt.config["ff.harness.environment_id"]
    return identifiers


def _create_harness_flag(
    identifier: str,
    name: str,
    api_key: str | None = None,
    description: str = "Autogenerated - do not edit",
    kind: FeatureConfigKind = FeatureConfigKind.BOOLEAN,
    variations: t.Optional[t.List[t.Dict[str, str]]] = None,
    **kwargs: t.Any,
) -> Result[dict]:
    """Create a flag in the Harness Platform API

    Args:
        identifier (str): The identifier for the flag
        name (str): The name for the flag
        kind (FeatureConfigKind): The kind of flag
        variations (dict): The variations for the flag
        **kwargs: Additional keyword arguments to pass to the Harness Platform API

    Returns:
        dict: The response from the Harness Platform API

    Raises:
        AssertionError: If the number of variations is less than two
        requests.exceptions.HTTPError: If the response from the Harness Platform API
            is not successful
    """
    if variations is None:
        variations = [
            {
                "identifier": "on-variation",
                "value": "true",
            },
            {
                "identifier": "off-variation",
                "value": "false",
            },
        ]
    assert len(variations) >= 2, "Must have at least two variations"
    resp = requests.post(
        "https://app.harness.io/gateway/cf/admin/features",
        params=_harness_identifiers(project=False),
        headers={
            "Content-Type": "application/json",
            "x-api-key": api_key or dlt.secrets["ff.harness.api_key"],
        },
        json={
            "defaultOnVariation": variations[0]["identifier"],
            "defaultOffVariation": variations[1]["identifier"],
            "description": description,
            "identifier": identifier,
            "name": name,
            "kind": kind.value,
            "permanent": True,
            "project": dlt.config["ff.harness.project"],
            "variations": variations,
            **kwargs,
        },
    )
    if resp.ok:
        return Result(resp.json(), None)
    return Result(None, Exception(resp.text))


@lru_cache(maxsize=1)
def _get_harness_flag(flag_id: str, api_key: str | None = None) -> Result[dict]:
    """Get a flag from the Harness Platform API

    Args:
        flag_id (str): The flag identifier

    Returns:
        dict: The flag

    Raises:
        requests.exceptions.HTTPError: If the request fails
    """
    resp = requests.get(
        f"https://app.harness.io/gateway/cf/admin/features/{flag_id}",
        headers={"x-api-key": api_key or dlt.secrets["ff.harness.api_key"]},
        params={**_harness_identifiers(environment=True), "metrics": False},
    )
    if resp.ok:
        return Result(resp.json(), None)
    return Result(None, Exception(resp.text))


def _harness_flag_exists(flag_id: str, ff_client: CfClient) -> bool:
    """Check if a flag exists in the Harness Platform API

    We make this fast by checking the SDK cache.

    Args:
        flag_id (str): The identifier for the flag

    Returns:
        bool: True if the flag exists, False otherwise
    """
    try:
        return f"flags/{flag_id}" in list(ff_client._repository.cache.keys()) or bool(
            Result.apply(_get_harness_flag, flag_id)
        )
    except requests.HTTPError as e:
        if e.response and e.response.status_code in (404, 400):
            return False
        raise


def _harness_id_to_component_id(harness_id: str) -> str:
    """Convert a Harness Platform API flag id to a component id

    Args:
        harness_id (str): The Harness Platform API flag id

    Returns:
        str: The component id
    """
    if harness_id.upper().startswith("FLAGS/"):
        harness_id = harness_id.split("/", 1)[1]
    return harness_id.replace("__", ":", 1)


def _component_id_to_harness_id(component_id: str) -> str:
    """Convert a component id to a Harness Platform API flag id

    Args:
        component_id (str): The component id

    Returns:
        str: The Harness Platform API flag id
    """
    return "__".join(component_id.split(":")[1:]).replace(".", "_")


def get_or_create_flag_harness(
    cache: TFlags,
    source: DltSource,
    /,
    workspace_name: str,
    workspace_path: Path,
    *,
    account: str | None = None,
    project: str | None = None,
    organization: str | None = None,
    sdk_key: str | None = None,
    api_key: str | None = None,
) -> TFlags:
    """Populate a cache with flags.

    Args:
        cache: A cache to populate.
        component_id: The id of the component to search for flags. Used to reduce the
            number of fetched flags. Additionally, if a flag for the given component id
            does not exist, we will create it.
        sdk_key: The sdk key to use to authenticate with harness.

    Returns:
        dict: The populated cache.
    """
    _ = workspace_path  # We don't need the path
    _ff_logger.setLevel(logging.ERROR)
    cache = cache if cache is not None else {}
    ff_client = _get_harness_client(sdk_key or dlt.secrets["ff.harness.sdk_key"])
    account, project, organization = (
        account or dlt.config["ff.harness.account"],
        project or dlt.config["ff.harness.project"],
        organization or dlt.config["ff.harness.organization"],
    )
    cache.update(
        {
            _harness_id_to_component_id(k): ff_client._repository.cache.get(k)
            for k in ff_client._repository.cache.keys()
        }
    )
    for resource in source.resources.keys():
        component = get_source_component_id(source, resource, workspace_name)
        if component in cache:
            continue
        harness_safeident = _component_id_to_harness_id(component)
        exists = _harness_flag_exists(harness_safeident, ff_client)
        if not exists:
            _create_harness_flag(
                harness_safeident,
                f"Extract {' '.join(component.split(':')[1:]).title()}",
                api_key=api_key or dlt.secrets["ff.harness.api_key"],
            )
            cache[component] = False
        else:
            rv = ff_client.bool_variation(harness_safeident, Target("cdf"), False)
            cache[component] = rv
    return cache


def get_or_create_flag_launchdarkly(
    cache: TFlags,
    source: DltSource,
    /,
    workspace_name: str,
    workspace_path: Path,
    *,
    account: str | None = None,
    api_key: str | None = None,
) -> TFlags:
    raise NotImplementedError


def get_or_create_flag_local(
    cache: TFlags,
    source: DltSource,
    /,
    workspace_name: str,
    workspace_path: Path,
    *,
    component_paths: t.Iterable[str | Path] | None = None,
    max_depth: int = 3,
) -> TFlags:
    """Populate a cache with flags.

    Args:
        cache: A cache to populate.
        component_id: The id of the component to search for flags. Used to filter the cache.
            This is not used for the local implementation but is a required parameter for
            the interface.
        component_paths: A list of paths to search for flags. Supplied via closure.

    Returns:
        dict: The populated cache.
    """
    if workspace_path is None:
        workspace_path = Path.cwd()
    cache = cache if cache is not None else {}

    component_paths = component_paths or [
        workspace_path / cp for cp in c.COMPONENT_PATHS
    ] + [Path.home() / ".cdf"]
    for raw_path in component_paths:
        cdf_logger.debug("Searching for flags in %s", raw_path)
        new_flags = {}

        # Search path
        path = Path(raw_path).expanduser().resolve()
        if path != Path.home():
            do(
                new_flags.update,
                map(lambda f: search_merge_json(path, f, max_depth), c.CDF_FLAG_FILES),
            )
        else:
            do(
                new_flags.update,
                map(
                    lambda f: json.loads((path / f).read_text()),
                    filter(lambda f: (path / f).exists(), c.CDF_FLAG_FILES),
                ),
            )

        # We want to ensure a single-project layout does not require default prefixed flags
        # And that in a multi-project layout, we can override flags with a working directory
        # based on the "project local" name.
        for key in list(new_flags.keys()):
            qkey = qualify_source_component_id(key, workspace_name)
            if qkey != key:
                new_flags[qkey] = new_flags.pop(key)
        cdf_logger.debug("Found flags: %s", new_flags)
        cache.update(new_flags)

    # TODO: make this a function
    with _LOCAL_CACHE_MUTEX:
        cwd_new_flags = {}
        for resource in source.resources.keys():
            component = get_source_component_id(source, resource, workspace_name)
            if component not in cache:
                cwd_new_flags[component] = False
        if cwd_new_flags:
            cdf_cwd = Path.cwd() / c.CDF_FLAG_FILES[0]
            cdf_logger.debug("Updating flags in %s", cdf_cwd)
            if cdf_cwd.exists():
                base_cwd_flags = json.loads(cdf_cwd.read_text())
                cwd_new_flags.update(base_cwd_flags)
            cdf_cwd.write_text(json.dumps(cwd_new_flags, indent=2))

    return cache


def toggle_flag_dispatch() -> Result:
    ...


def delete_flag_dispatch() -> Result:
    ...


def get_or_create_flag_dispatch(
    cache: TFlags,
    source: DltSource,
    /,
    workspace_name: str,
    workspace_path: Path,
    *,
    with_provider: Providers | None = None,
    **kwargs: t.Any,
) -> TFlags:
    """Populate a cache with flags.

    This function dispatches to the appropriate implementation based on the
    provider specified in the config.
    """
    kwargs["workspace_name"] = workspace_name
    kwargs["workspace_path"] = workspace_path
    provider: Providers = with_provider or dlt.config["ff.provider"]
    if provider == "local":
        return get_or_create_flag_local(cache, source, **kwargs)
    elif provider == "harness":
        return get_or_create_flag_harness(cache, source, **kwargs)
    elif provider == "launchdarkly":
        return get_or_create_flag_launchdarkly(cache, source, **kwargs)
    else:
        raise ValueError(
            f"Invalid provider: {provider}, must be one of {t.get_args(Providers)}"
        )


def get_source_ff(
    source: DltSource,
    populate_cache_fn: FnPopulateCache = get_or_create_flag_dispatch,
    cache: TFlagsSource | None = None,
    workspace_name: str | None = None,
    workspace_path: str | Path | None = None,
) -> TFlags:
    """Get flags for a specific component id populating the cache if needed.

    Args:
        component_id: The component to find. In the form of <source|transform|publisher>:<name>
            For a source, the <name> is <source_name>:<resource_name>
        populate_cache_fn: A function which takes a cache dict and component id and populates
            the cache. The implementer can make decisions on how to interface with the network
            given the supplied component id which is a prefix for the requested flags. The
            implementer should also decide what to do if the component_id is not found in the
            cache. Typically this means creating a flag in the feature flag provider.

    Returns:
        dict: The flags for the source
    """
    if workspace_name is None:
        workspace_name = c.DEFAULT_WORKSPACE
    workspace_path = Path(workspace_path or ".").expanduser().resolve()
    cdf_logger.debug("Getting flags for %s in path %s", source.name, workspace_path)
    cache = cache if cache is not None else CACHE
    if source not in cache:
        cache[source] = populate_cache_fn({}, source, workspace_name, workspace_path)
    return cache[source]


def apply_feature_flags(
    source: DltSource,
    flags: t.Dict[str, bool],
    workspace: str | None = None,
    raise_on_no_resources: bool = False,
) -> DltSource:
    """Apply feature flags to a source."""

    for resource in source.resources.values():
        key = get_source_component_id(source, resource, workspace)
        fv = flags.get(key)
        if fv is None:
            cdf_logger.debug("No flag for %s", key)
            fv = False
        elif fv is False:
            cdf_logger.debug("Flag for %s is False", key)
        elif fv is True:
            cdf_logger.debug("Flag for %s is True", key)
        resource.selected = fv

    if raise_on_no_resources and not source.resources.selected:
        raise ValueError(f"No resources selected for source {source.name}")

    return source
